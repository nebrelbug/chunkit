# Single Benchmark Configuration
# Comprehensive tokenizer evaluation across language groups

benchmark:
  total_samples: 10000  # Reduced for faster testing
  max_text_length: 2048
  output_dir: "./benchmarks"

# Configure which external tokenizers to test
tokenizers:
  - name: "GPT-2"
    model: "gpt2"
    enabled: true
  
  - name: "GPT-4"
    model: "Xenova/gpt-4"
    enabled: true
  
  - name: "LLaMA-3.3"
    model: "meta-llama/Llama-3.3-70B-Instruct"
    enabled: false  # Disable for faster testing
  
  - name: "Mixtral"
    model: "mistralai/Mixtral-8x22B-Instruct-v0.1"
    enabled: false
    requires_sentencepiece: true

# Auto-discover custom tokenizers
custom_tokenizers:
  enabled: true
  directory: "./tokenizers"
  name_pattern: "Custom-{folder_name}"

# Dataset groups for structured evaluation
dataset_groups:
  - name: "High-Resource Languages"
    description: "English, Chinese, Spanish - most common world languages"
    sample_allocation: 0.4  # 40% of total samples (120 samples)
    datasets:
      - path: "HuggingFaceFW/fineweb"
        subsets:
          - name: "sample-10BT"
            text_column: "text"
      
      - path: "HuggingFaceFW/fineweb-2"
        subsets:
          - name: "cmn_Hani"  # Chinese
            text_column: "text"
          - name: "spa_Latn"  # Spanish
            text_column: "text"

  - name: "Mid-Resource Languages"
    description: "German, French, Japanese - common languages"
    sample_allocation: 0.3  # 30% of total samples (90 samples)
    datasets:
      - path: "HuggingFaceFW/fineweb-2"
        subsets:
          - name: "deu_Latn"  # German
            text_column: "text"
          - name: "fra_Latn"  # French
            text_column: "text"

  - name: "Programming Languages"
    description: "Python, JavaScript"
    sample_allocation: 0.3  # 30% of total samples (90 samples)
    datasets:
      - path: "bigcode/starcoderdata"
        subsets:
          - name: "python"
            text_column: "content"
          - name: "javascript"
            text_column: "content" 