# Benchmark configuration for tokenizer evaluation
# Includes diverse languages and domains for comprehensive testing

training:
  total_samples: 10_000  # Total samples across all datasets
  streaming_enabled: true
  output_dir: "./benchmarks/test1"
  temperature: 0.3
  min_samples_per_lang: 100
  max_samples_per_lang: 1000

datasets:
  # English - baseline
  - path: "HuggingFaceFW/fineweb"
    description: "English web data"
    subsets:
      - name: "sample-10BT"
        priority: 5

  # Major world languages
  - path: "HuggingFaceFW/fineweb-2"
    description: "Multilingual web data"
    subsets:
      - name: "rus_Cyrl"  # Russian
        priority: 4
      - name: "cmn_Hani"  # Chinese
        priority: 4
      - name: "deu_Latn"  # German
        priority: 4
      - name: "jpn_Jpan"  # Japanese
        priority: 4
      - name: "spa_Latn"  # Spanish
        priority: 4
      - name: "fra_Latn"  # French
        priority: 4

  # Programming languages
  - path: "bigcode/starcoderdata"
    description: "Programming languages"
    subsets:
      - name: "python"
        priority: 4
        text_column: "content"
      - name: "javascript"
        priority: 3
        text_column: "content"
      - name: "typescript"
        priority: 3
        text_column: "content"
      - name: "java"
        priority: 3
        text_column: "content"
      - name: "cpp"
        priority: 3
        text_column: "content"
      - name: "go"
        priority: 3
        text_column: "content" 